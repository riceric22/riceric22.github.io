---
layout: skeleton
---
[site]: https://www.cis.upenn.edu/~exwong/arga/

*Disclaimer: In the spirit of this course, this website is being developed with the assistance of Generative AI tools.*

# [CIS 7000: Accelerating Research with Generative AI (Fall 2025)][site]

This seminar explores practical approaches for researchers to effectively utilize Generative AI models through hands-on experimentation and exploration. Students will investigate applying these models to research tasks such as summarizing literature, writing assistance, code development, and visual aid creation. Potential topics include effective prompting, critical evaluation of outputs, and responsible use considerations including relevant ethics and safety. Students are expected to be familiar with and actively engaged in research methodology.

## Course Structure and Expectations

This hands-on seminar requires active student engagement in discussions and explorations of GenAI tools. Students will experiment with applying LLMs and other generative models to various research tasks (similar to those listed below), focusing on prompt engineering, utilizing different platforms, and analyzing results. A key component involves critically evaluating AI outputs for accuracy, bias, relevance, and ethical implications. The course culminates in a project where students apply GenAI to accelerate a part of their own research pipeline or a defined problem, evaluating its effectiveness and sharing their findings and techniques with the class.

---

**Instructor**: [Eric Wong](https://www.cis.upenn.edu/~exwong) ([exwong@cis](mailto:exwong@cis.upenn.edu))

**Class**: TBD

**Website**: [https://www.cis.upenn.edu/~exwong/arga/][site]

**Registration**: To register, you need to sign up both on [courses.upenn.edu](https://courses.upenn.edu/) and also submit the questionaire on the [CIS waitlist](https://advising.cis.upenn.edu/waitlist/).

---

## Potential Applications / Topics

This course will delve into how Large Language Models (LLMs) can be applied across the research lifecycle. We will explore and experiment with tasks such as:

**I. Ideation and Literature Review**

* **Topic Exploration & Brainstorming:** Generating research questions, exploring related concepts, identifying potential angles.
* **Literature Discovery:** Suggesting relevant papers, authors, or journals based on initial ideas or abstracts.
* **Paper Summarization:** Creating concise summaries of research papers or specific sections.
* **Understanding Complex Concepts:** Explaining difficult methodologies, theories, or terminology found in papers.
* **Identifying Research Gaps:** Analyzing existing literature (provided by the user) to highlight underexplored areas.
* **Synthesizing Information:** Grouping related findings or arguments from multiple sources.
* **Translation:** Translating abstracts or key sections of papers written in other languages.

**II. Research Design and Planning**

* **Methodology Brainstorming:** Suggesting potential experimental designs or data analysis techniques.
* **Grant Proposal Assistance:** Drafting sections like literature review, background, or potential impact.
* **Data Management Planning:** Outlining potential data organization strategies or documentation needs.

**III. Data Collection and Experimentation**

* **Survey/Questionnaire Design:** Generating draft questions or structuring survey flow.
* **Code Generation (Simulations/Scripts):** Creating initial code drafts for simulations, data processing scripts, or experimental setups (e.g., Python, R, MATLAB).
* **Generating Synthetic Data (Use with Caution):** Creating placeholder or example datasets for testing analysis pipelines (requires careful validation).

**IV. Data Analysis and Interpretation**

* **Code Generation (Analysis):** Writing code snippets for specific statistical analyses or data visualization using libraries (e.g., Python's Matplotlib/Seaborn, R's ggplot2).
* **Code Debugging:** Identifying errors or suggesting improvements in analysis scripts.
* **Code Documentation:** Generating comments or explanations for code sections.
* **Qualitative Data Exploration:** Assisting in thematic analysis by suggesting potential themes or categories in text data (requires significant human oversight).
* **Interpreting Results:** Rephrasing complex statistical outputs into more understandable language (verify accuracy carefully).

**V. Writing and Manuscript Preparation**

* **Drafting Assistance:** Generating initial drafts for sections like Introduction (background), Methods (descriptions based on user input), or Discussion (potential interpretations).
* **Rephrasing and Paraphrasing:** Rewriting sentences or paragraphs to improve clarity, flow, or conciseness, or to avoid repetition.
* **Grammar and Style Checking:** Identifying grammatical errors, suggesting stylistic improvements, and ensuring consistency.
* **Abstract Generation:** Creating draft abstracts based on the main findings and manuscript content.
* **Citation Management Assistance:** Formatting references based on specific style guides (though dedicated tools are often better).
* **Generating Figure/Table Captions:** Drafting descriptive captions based on the data presented.

**VI. Dissemination and Presentation**

* **Presentation Outline Creation:** Generating a logical structure for a research talk.
* **Slide Content Generation:** Drafting text points, summaries, or explanations for presentation slides.
* **Speaker Note Generation:** Creating draft speaker notes to accompany slides.
* **Visual Aid Ideas:** Suggesting types of visuals (charts, diagrams) appropriate for presenting specific data or concepts.
* **Poster Content Generation:** Assisting in drafting text sections for academic posters.
* **Responding to Reviewers:** Helping draft responses to reviewer comments by outlining arguments or rephrasing points.
* **Lay Summaries:** Translating technical research findings into language accessible to a general audience.

**Important Considerations:**

Throughout the course, we will emphasize:

* **Accuracy & Verification:** LLM outputs must always be critically evaluated for factual accuracy, correctness (especially code), and potential biases.
* **Originality & Plagiarism:** Ensure that LLM-generated text is properly attributed or significantly rewritten to avoid plagiarism. Understand journal/conference policies on AI use.
* **Confidentiality:** Be cautious about inputting sensitive or unpublished data into public LLMs.
* **Ethical Use:** Consider the ethical implications of using AI in research, including data privacy and potential biases in the models themselves.
