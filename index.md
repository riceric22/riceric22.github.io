---
layout: page
title: Eric Wong
subtitle: Assistant Professor, University of Pennsylvania
---

|--|--|
| Office | [Levine 506](https://goo.gl/maps/yZmpgFMjUKhGnpXb6) |
| Email | [exwong@cis](mailto:exwong@cis.upenn.edu) |
| Lab Blog | [debugml.github.io](https://debugml.github.io/)

I am an assistant professor at the [Department of Computer and Information Science](https://www.cis.upenn.edu/) at the University of Pennsylvania. I lead [Brachio Lab](https://brachiolab.github.io/) on debugging machine learning and making systems actually do what we want them to do. I'm also a part of the [ASSET Center](https://blog.seas.upenn.edu/penn-engineerings-new-asset-center-will-focus-on-the-safety-explainability-and-trustworthiness-of-ai-systems/) on safe, explainable, and trustworthy AI systems. Previously, I completed my PhD at CMU advised by [Zico Kolter](https://zicokolter.com/), and did a postdoc with [Aleksander Madry](https://people.csail.mit.edu/madry/). 

*PhD applicants*: If you're interested, you will need to 

1. Apply to the [CIS department](https://www.cis.upenn.edu/graduate/program-offerings/doctoral-program/) 
2. Select me as a potential advisor in your application. 

*Undergraduates/masters students*: If you are a UPenn student and are interested in doing independent machine learning research, then I would recommend (1) take CIS 5200 (2) read this [blog post](https://www.alextamkin.com/essays/tips-for-new-researchers), and (3) fill out [this form](https://forms.gle/AXx3JfKCEsLPC6Wx5). We will be in touch if there is a good fit. I strongly recommend undergraduates take [CIS 3333 Mathematics for Machine Learning](https://www.cis.upenn.edu/~exwong/moml/), which will prepare you for the mathematics behind ML research. If you're interested in doing advanced research or graduate coursework in AI/machine learning but have taken only the core math requirements of the CS degree, then this course is for you. If you are not at UPenn, I do not currently have opportunities for external students. 

### Recent News
+ July '24: We will present two papers at ICML 2024: ["DISCRET: Synthesizing Faithful Explanations For Treatment Effect Estimation"](https://arxiv.org/abs/2406.00611) and ["Towards Compositionality in Concept Learning"](https://arxiv.org/abs/2406.00611). 
+ May '24: Our paper ["Evaluating Groups of Features via Consistency, Contiguity, and Stability"](https://openreview.net/forum?id=IP2etbIEuC) will be presented at ICLR 2024 as an oral. 
+ April '24: We've been given an [Amazon Research Award](https://www.amazon.science/research-awards/program-updates/99-amazon-research-awards-recipients-announced). Thanks Amazon! 
+ October '23: We've released new blog posts on [faithful grouped attributions](https://debugml.github.io/sum-of-parts/) and [certified jailbreak defenses](https://debugml.github.io/smooth-llm/). We've also released new work on [semantic jailbreaks](https://jailbreaking-llms.github.io/)
+ October '23: I gave a talk at the [UCSB Responsible Machine Learning Summit](https://ml.ucsb.edu/events/summit/responsible-machine-learning-summit-2023) 
+ September '23: Our paper ["Stability Guarantees for Feature Attributions with Multiplicative Smoothing"](https://arxiv.org/abs/2307.05902) will be presented at NeurIPS 2023
+ July '23: We released a new blog post on [certified stability guarantees for feature attributions](https://debugml.github.io/multiplicative-smoothing/)
+ July '23: Our paper ["Do Machine Learning Models Learn Statistical Rules Inferred from Data?"](https://arxiv.org/abs/2303.01433) will be presented at ICML 2023
+ May '23: I gave a keynote talk at [DLSP 2023](https://dls2023.ieee-security.org/) on adversarial prompting
+ Mar '22: I am on the organizing committee for the ICML 2023 [2nd Workshop on New Frontiers in Adversarial Machine Learning](https://advml-frontier.github.io/)
+ Mar '23: We've released a new [blog post](https://debugml.github.io/adversarial-prompts/) covering our recent work on *adversarial prompting*
+ Mar '23: We've released a new [blog post](https://debugml.github.io/incontext-influences/) covering our recent work on *in-context influences*
+ Jan '23: I am teaching CIS 5200 Machine Learning with [Surbhi Goel](https://www.surbhigoel.com/)
+ July '22: I am creating a new course on [debugging the ML pipeline]({{ site.baseurl }}{% link debugml.md %}) for the Fall 2022 semester 
+ May '22: I will be moving to UPenn CIS as an Assistant Professor starting Fall 2022

<!-- 
+ March '22: I am on the organizing committee for the ICML 2022 [Workshop on New Frontiers in Adversarial Machine Learning](https://advml-frontier.github.io/)
+ March '22: Our paper "Certified Patch Robustness via Smoothed Vision Transformers" was accepted at CVPR 2022
+ January '22: Our paper "Missingness Bias in Model Debugging" was accepted at ICLR 2022 
-->

<!-- + 10/18/21: I will be speaking as a panelist for the [ATVA 2021 Workshop on Security and Reliability of Machine Learning (SRML)](https://sites.google.com/view/srml-atva2021)
+ 10/12/21: I am on the organizing committee for the AAAI 2022 [Workshop on Adversarial Machine Learning and Beyond](https://advml-workshop.github.io/aaai2022/)
+ 5/12/21: Our paper "Leveraging sparse linear layers for debuggable deep networks" was accepted for a long oral presentation at ICML 2021
+ 4/7/21: I am on the organizing committee for the ICML 2021 workshop [A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning](https://advml-workshop.github.io/icml2021/)
+ 1/12/21: Our paper "Learning perturbation sets for robust machine learning" was accepted for a poster at ICLR 2021
+ 12/14/20: I am a main organizer for the ICLR 2021 workshop [Robust and Reliable Machine learning in the Real World](https://sites.google.com/connect.hku.hk/robustml-2021/home) 
+ 8/1/20: I have started my postdoc at MIT with Aleksander Madry
 -->
