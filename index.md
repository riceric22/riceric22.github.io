---
layout: page
title: Eric Wong
subtitle: Assistant Professor, University of Pennsylvania
---

|--|--|
| Office | [Amy Gutman Hall 621](https://goo.gl/maps/yZmpgFMjUKhGnpXb6) |
| Email | [exwong@cis](mailto:exwong@cis.upenn.edu) |
| Lab Blog | [debugml.github.io](https://debugml.github.io/)

I am an assistant professor at the [Department of Computer and Information Science](https://www.cis.upenn.edu/) at the University of Pennsylvania. I lead [Brachio Lab](https://brachiolab.github.io/) on debugging machine learning and making systems actually do what we want them to do. I'm also a part of the [ASSET Center](https://blog.seas.upenn.edu/penn-engineerings-new-asset-center-will-focus-on-the-safety-explainability-and-trustworthiness-of-ai-systems/) on safe, explainable, and trustworthy AI systems. Previously, I completed my PhD at CMU advised by [Zico Kolter](https://zicokolter.com/), and did a postdoc with [Aleksander Madry](https://people.csail.mit.edu/madry/). 

{: .box-success}
We'll be at NeurIPS 2025 to present: <br>+ [Probabilistic Stability Guarantees for Feature Attributions](https://debugml.github.io/soft-stability/)<br>+ [CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic Learning](https://arxiv.org/abs/2503.24123)<br>+ [Once Upon an Input: Reasoning via Per-Instance Program Synthesis](https://neurips.cc/virtual/2025/poster/117467)<br> and also EMNLP 2025 to present: <br>+ [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948) <br>+ [Adaptively profiling models with task elicitation](https://arxiv.org/abs/2503.01986) 

*PhD applicants*: If you're interested, you will need to 

1. Apply to the [CIS department](https://www.cis.upenn.edu/graduate/program-offerings/doctoral-program/) 
2. Select me as a potential advisor in your application. 

*Undergraduates/masters students*: If you are a UPenn student and are interested in doing independent machine learning research, then I would recommend (1) take CIS 5200 (2) read this [blog post](https://www.alextamkin.com/essays/tips-for-new-researchers), and (3) fill out [this form](https://forms.gle/AXx3JfKCEsLPC6Wx5). We will be in touch if there is a good fit. I strongly recommend undergraduates take [CIS 3333 Mathematics for Machine Learning](https://www.cis.upenn.edu/~exwong/moml/), which will prepare you for the mathematics behind ML research. If you're interested in doing advanced research or graduate coursework in AI/machine learning but have taken only the core math requirements of the CS degree, then this course is for you. If you are not at UPenn, I do not currently have opportunities for external students. 

### Recent News
+ July '25: I gave talks on the following topics at ICML workshops: Safety alignment at the [DIG-BUGS Workshop](https://icml2025digbugs.github.io/), Rule-following theory for principled steering at the [MOSS Workshop](https://sites.google.com/view/moss2025), and Certified explanations for experts at the [Actionable Interpretability Workshop](https://actionable-interpretability.github.io/)
+ June '25: Our paper, ["The FIX Benchmark: Extracting Features Interpretable to eXperts"](https://brachiolab.github.io/fix/) was accepted to DMLR 2025. 
+ May '25: [Weiqiu You](https://fallcat.github.io/)'s paper, ["Sum-of-Parts: Self-Attributing Neural Networks with End-to-End Learning of Feature Groups"](https://arxiv.org/abs/2310.16316), as well as another collaboration "DOLPHIN: A Programmable Framework for Scalable Neurosymbolic Learning" was accepted to ICML 2025. Our [FIX Benchmark](https://brachiolab.github.io/fix/) was also accepted to DMLR. 
+ January '25: Our paper, ["Logicbreaks: A Framework for Understanding Subversion of Rule-based Inference"](https://arxiv.org/abs/2407.00075) has been accepted to ICLR 2025. In addition, ["Avoiding Copyright Infringement via Machine Unlearning"](https://arxiv.org/abs/2406.10952) has been accepted to NAACL-Findings 2025. 
+ December '24: We will present three papers at NeurIPS 2024 this month: ["AR-Pro: Counterfactual Explanations for Anomaly Repair with Formal Properties"](https://arxiv.org/abs/2410.24178), ["Data-Efficient Learning with Neural Programs"](https://arxiv.org/abs/2406.06246), and ["JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models"](https://arxiv.org/abs/2404.01318). 
+ October '24: We've released the [FIX benchmark](https://brachiolab.github.io/fix/) for extracting features interpretable to experts! Check it out at our website [here](https://brachiolab.github.io/fix/)
+ July '24: We will present two papers at ICML 2024: ["DISCRET: Synthesizing Faithful Explanations For Treatment Effect Estimation"](https://arxiv.org/abs/2406.00611) and ["Towards Compositionality in Concept Learning"](https://arxiv.org/abs/2406.00611). 
+ May '24: Our paper ["Evaluating Groups of Features via Consistency, Contiguity, and Stability"](https://openreview.net/forum?id=IP2etbIEuC) will be presented at ICLR 2024 as an oral. 
+ April '24: We've been given an [Amazon Research Award](https://www.amazon.science/research-awards/program-updates/99-amazon-research-awards-recipients-announced). Thanks Amazon! 
+ October '23: We've released new blog posts on [faithful grouped attributions](https://debugml.github.io/sum-of-parts/) and [certified jailbreak defenses](https://debugml.github.io/smooth-llm/). We've also released new work on [semantic jailbreaks](https://jailbreaking-llms.github.io/)
+ October '23: I gave a talk at the [UCSB Responsible Machine Learning Summit](https://ml.ucsb.edu/events/summit/responsible-machine-learning-summit-2023) 
+ September '23: Our paper ["Stability Guarantees for Feature Attributions with Multiplicative Smoothing"](https://arxiv.org/abs/2307.05902) will be presented at NeurIPS 2023
+ July '23: We released a new blog post on [certified stability guarantees for feature attributions](https://debugml.github.io/multiplicative-smoothing/)
+ July '23: Our paper ["Do Machine Learning Models Learn Statistical Rules Inferred from Data?"](https://arxiv.org/abs/2303.01433) will be presented at ICML 2023
+ May '23: I gave a keynote talk at [DLSP 2023](https://dls2023.ieee-security.org/) on adversarial prompting
+ Mar '22: I am on the organizing committee for the ICML 2023 [2nd Workshop on New Frontiers in Adversarial Machine Learning](https://advml-frontier.github.io/)
+ Mar '23: We've released a new [blog post](https://debugml.github.io/adversarial-prompts/) covering our recent work on *adversarial prompting*
+ Mar '23: We've released a new [blog post](https://debugml.github.io/incontext-influences/) covering our recent work on *in-context influences*
+ Jan '23: I am teaching CIS 5200 Machine Learning with [Surbhi Goel](https://www.surbhigoel.com/)
+ July '22: I am creating a new course on [debugging the ML pipeline]({{ site.baseurl }}{% link debugml.md %}) for the Fall 2022 semester 
+ May '22: I will be moving to UPenn CIS as an Assistant Professor starting Fall 2022

<!-- 
+ March '22: I am on the organizing committee for the ICML 2022 [Workshop on New Frontiers in Adversarial Machine Learning](https://advml-frontier.github.io/)
+ March '22: Our paper "Certified Patch Robustness via Smoothed Vision Transformers" was accepted at CVPR 2022
+ January '22: Our paper "Missingness Bias in Model Debugging" was accepted at ICLR 2022 
-->

<!-- + 10/18/21: I will be speaking as a panelist for the [ATVA 2021 Workshop on Security and Reliability of Machine Learning (SRML)](https://sites.google.com/view/srml-atva2021)
+ 10/12/21: I am on the organizing committee for the AAAI 2022 [Workshop on Adversarial Machine Learning and Beyond](https://advml-workshop.github.io/aaai2022/)
+ 5/12/21: Our paper "Leveraging sparse linear layers for debuggable deep networks" was accepted for a long oral presentation at ICML 2021
+ 4/7/21: I am on the organizing committee for the ICML 2021 workshop [A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning](https://advml-workshop.github.io/icml2021/)
+ 1/12/21: Our paper "Learning perturbation sets for robust machine learning" was accepted for a poster at ICLR 2021
+ 12/14/20: I am a main organizer for the ICLR 2021 workshop [Robust and Reliable Machine learning in the Real World](https://sites.google.com/connect.hku.hk/robustml-2021/home) 
+ 8/1/20: I have started my postdoc at MIT with Aleksander Madry
 -->
